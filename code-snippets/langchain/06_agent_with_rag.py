"""
Agent + RAG ç»“åˆæ•™ç¨‹

æ ¸å¿ƒæ¦‚å¿µï¼š
1. å•çº¯ RAGï¼šç”¨æˆ·é—® â†’ æ£€ç´¢ â†’ å›ç­”ï¼ˆä¸€æ¬¡æ€§ï¼Œè¢«åŠ¨ï¼‰
2. Agent + RAGï¼šAgent è‡ªå·±å†³å®šä»€ä¹ˆæ—¶å€™éœ€è¦æŸ¥çŸ¥è¯†åº“ï¼ˆä¸»åŠ¨ï¼‰
3. å¤šå·¥å…·åä½œï¼šRAG åªæ˜¯ Agent çš„å·¥å…·ä¹‹ä¸€

åº”ç”¨åœºæ™¯ï¼š
- æ™ºèƒ½å®¢æœï¼šæŸ¥çŸ¥è¯†åº“ + åˆ›å»ºå·¥å• + è½¬äººå·¥
- ä¼ä¸šåŠ©æ‰‹ï¼šæŸ¥æ–‡æ¡£ + å‘é‚®ä»¶ + é¢„çº¦ä¼šè®®
- ä»£ç åŠ©æ‰‹ï¼šæŸ¥æ–‡æ¡£ + æ‰§è¡Œä»£ç  + æœç´¢ç½‘ç»œ

è¿è¡Œï¼š
cd ai-agent-learning
source .venv/bin/activate
python code-snippets/langchain/06_agent_with_rag.py
"""

import os
from dotenv import load_dotenv

load_dotenv()

# ============================================================
# API é…ç½®
# ============================================================

# iFlow - ç”¨äºå¯¹è¯
IFLOW_API_KEY = os.getenv("IFLOW_API_KEY")
IFLOW_BASE_URL = os.getenv("IFLOW_BASE_URL", "https://apis.iflow.cn/v1")
IFLOW_MODEL = os.getenv("IFLOW_MODEL", "qwen3-coder-plus")

# SiliconFlow - ç”¨äº Embedding
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
SILICONFLOW_BASE_URL = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")
SILICONFLOW_EMBEDDING_MODEL = os.getenv("SILICONFLOW_EMBEDDING_MODEL", "BAAI/bge-m3")


def get_embeddings():
    """è·å– Embedding æ¨¡å‹"""
    if SILICONFLOW_API_KEY and SILICONFLOW_API_KEY != "your_siliconflow_api_key_here":
        from langchain_openai import OpenAIEmbeddings
        return OpenAIEmbeddings(
            model=SILICONFLOW_EMBEDDING_MODEL,
            openai_api_key=SILICONFLOW_API_KEY,
            openai_api_base=SILICONFLOW_BASE_URL,
        )
    else:
        # å›é€€åˆ°æœ¬åœ°æ¨¡å‹
        from sentence_transformers import SentenceTransformer
        
        class LocalEmbeddings:
            def __init__(self):
                self.model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            
            def embed_documents(self, texts):
                return self.model.encode(texts, convert_to_numpy=True).tolist()
            
            def embed_query(self, text):
                return self.model.encode(text, convert_to_numpy=True).tolist()
        
        return LocalEmbeddings()


def get_llm():
    """è·å– LLM"""
    from langchain_openai import ChatOpenAI
    return ChatOpenAI(
        model=IFLOW_MODEL,
        openai_api_key=IFLOW_API_KEY,
        openai_api_base=IFLOW_BASE_URL,
    )


# ============================================================
# Demo 1: å•çº¯ RAG vs Agent + RAG çš„åŒºåˆ«
# ============================================================

def demo_1_difference():
    """å¯¹æ¯”å•çº¯ RAG å’Œ Agent + RAG"""
    print("\n" + "=" * 60)
    print("Demo 1: å•çº¯ RAG vs Agent + RAG")
    print("=" * 60)
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å•çº¯ RAGï¼ˆè¢«åŠ¨æ£€ç´¢ï¼‰                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ç”¨æˆ·: "å…¬å¸è¯·å‡æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"                               â”‚
â”‚         â†“                                                   â”‚
â”‚  ç³»ç»Ÿ: æ£€ç´¢çŸ¥è¯†åº“ â†’ è¿”å›ç­”æ¡ˆ                                â”‚
â”‚                                                             â”‚
â”‚  ç‰¹ç‚¹ï¼š                                                     â”‚
â”‚  - æ¯æ¬¡éƒ½æ£€ç´¢ï¼ˆä¸ç®¡éœ€ä¸éœ€è¦ï¼‰                               â”‚
â”‚  - åªèƒ½å›ç­”çŸ¥è¯†åº“é‡Œçš„é—®é¢˜                                   â”‚
â”‚  - æ— æ³•æ‰§è¡Œå…¶ä»–æ“ä½œ                                         â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Agent + RAGï¼ˆä¸»åŠ¨å†³ç­–ï¼‰                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ç”¨æˆ·: "å¸®æˆ‘æŸ¥ä¸€ä¸‹è¯·å‡æµç¨‹ï¼Œç„¶åå¸®æˆ‘è¯·3å¤©å‡"                â”‚
â”‚         â†“                                                   â”‚
â”‚  Agent æ€è€ƒ: éœ€è¦ä¸¤æ­¥                                       â”‚
â”‚    1. å…ˆç”¨ RAG å·¥å…·æŸ¥è¯¢è¯·å‡æµç¨‹                             â”‚
â”‚    2. å†ç”¨è¯·å‡å·¥å…·æäº¤ç”³è¯·                                  â”‚
â”‚         â†“                                                   â”‚
â”‚  Agent æ‰§è¡Œ: è°ƒç”¨å·¥å…· â†’ è¿”å›ç»“æœ                            â”‚
â”‚                                                             â”‚
â”‚  ç‰¹ç‚¹ï¼š                                                     â”‚
â”‚  - è‡ªå·±å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢                                     â”‚
â”‚  - å¯ä»¥ç»„åˆå¤šä¸ªå·¥å…·å®Œæˆå¤æ‚ä»»åŠ¡                             â”‚
â”‚  - æ›´æ™ºèƒ½ã€æ›´çµæ´»                                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")


# ============================================================
# Demo 2: åˆ›å»ºçŸ¥è¯†åº“ï¼ˆå‘é‡æ•°æ®åº“ï¼‰
# ============================================================

def create_knowledge_base():
    """åˆ›å»ºå…¬å¸çŸ¥è¯†åº“"""
    from langchain_community.vectorstores import FAISS
    from langchain_core.documents import Document
    
    # æ¨¡æ‹Ÿå…¬å¸å†…éƒ¨æ–‡æ¡£
    documents = [
        # è¯·å‡ç›¸å…³
        Document(
            page_content="è¯·å‡æµç¨‹ï¼šå‘˜å·¥éœ€è¦æå‰3å¤©åœ¨OAç³»ç»Ÿæäº¤è¯·å‡ç”³è¯·ï¼Œç”±ç›´å±é¢†å¯¼å®¡æ‰¹ã€‚ç—…å‡éœ€è¦æä¾›åŒ»é™¢è¯æ˜ã€‚",
            metadata={"category": "è¯·å‡", "source": "å‘˜å·¥æ‰‹å†Œ"}
        ),
        Document(
            page_content="å¹´å‡è§„å®šï¼šå·¥ä½œæ»¡1å¹´äº«æœ‰5å¤©å¹´å‡ï¼Œæ»¡5å¹´äº«æœ‰10å¤©ï¼Œæ»¡10å¹´äº«æœ‰15å¤©ã€‚å¹´å‡å¯åˆ†æ¬¡ä½¿ç”¨ï¼Œä½†éœ€æå‰ç”³è¯·ã€‚",
            metadata={"category": "è¯·å‡", "source": "å‘˜å·¥æ‰‹å†Œ"}
        ),
        Document(
            page_content="ç—…å‡è§„å®šï¼šç—…å‡éœ€è¦æä¾›æ­£è§„åŒ»é™¢çš„è¯Šæ–­è¯æ˜ã€‚3å¤©ä»¥å†…ç”±éƒ¨é—¨é¢†å¯¼å®¡æ‰¹ï¼Œ3å¤©ä»¥ä¸Šéœ€HRå®¡æ‰¹ã€‚",
            metadata={"category": "è¯·å‡", "source": "å‘˜å·¥æ‰‹å†Œ"}
        ),
        
        # æŠ¥é”€ç›¸å…³
        Document(
            page_content="æŠ¥é”€æµç¨‹ï¼šè´¹ç”¨å‘ç”Ÿå30å¤©å†…ï¼Œåœ¨è´¢åŠ¡ç³»ç»Ÿæäº¤æŠ¥é”€ç”³è¯·ï¼Œé™„ä¸Šå‘ç¥¨åŸä»¶å’Œå®¡æ‰¹å•ã€‚500å…ƒä»¥ä¸‹éƒ¨é—¨ç»ç†å®¡æ‰¹ï¼Œ500å…ƒä»¥ä¸Šéœ€æ€»ç›‘å®¡æ‰¹ã€‚",
            metadata={"category": "æŠ¥é”€", "source": "è´¢åŠ¡åˆ¶åº¦"}
        ),
        Document(
            page_content="å·®æ—…æŠ¥é”€æ ‡å‡†ï¼šé£æœºç»æµèˆ±ã€é«˜é“äºŒç­‰åº§ã€‚ä½å®¿æ ‡å‡†ï¼šä¸€çº¿åŸå¸‚500å…ƒ/æ™šï¼ŒäºŒçº¿åŸå¸‚350å…ƒ/æ™šã€‚",
            metadata={"category": "æŠ¥é”€", "source": "è´¢åŠ¡åˆ¶åº¦"}
        ),
        
        # ITç›¸å…³
        Document(
            page_content="VPNä½¿ç”¨ï¼šä¸‹è½½å…¬å¸VPNå®¢æˆ·ç«¯ï¼Œä½¿ç”¨å·¥å·ç™»å½•ã€‚é¦–æ¬¡ä½¿ç”¨éœ€è¦ITéƒ¨é—¨å¼€é€šæƒé™ï¼Œè”ç³»ITçƒ­çº¿ï¼š8888ã€‚",
            metadata={"category": "IT", "source": "ITæŒ‡å—"}
        ),
        Document(
            page_content="ç”µè„‘æ•…éšœå¤„ç†ï¼šå…ˆå°è¯•é‡å¯ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè”ç³»ITçƒ­çº¿8888æˆ–æäº¤ITå·¥å•ã€‚ç´§æ€¥é—®é¢˜å¯ç›´æ¥æ‰¾ITéƒ¨é—¨ã€‚",
            metadata={"category": "IT", "source": "ITæŒ‡å—"}
        ),
        
        # ä¼šè®®å®¤ç›¸å…³
        Document(
            page_content="ä¼šè®®å®¤é¢„çº¦ï¼šåœ¨OAç³»ç»Ÿçš„ä¼šè®®å®¤é¢„çº¦æ¨¡å—è¿›è¡Œé¢„çº¦ã€‚å¤§ä¼šè®®å®¤ï¼ˆ20äººä»¥ä¸Šï¼‰éœ€è¦æå‰1å¤©é¢„çº¦ã€‚",
            metadata={"category": "è¡Œæ”¿", "source": "è¡Œæ”¿æŒ‡å—"}
        ),
    ]
    
    embeddings = get_embeddings()
    vectorstore = FAISS.from_documents(documents, embeddings)
    return vectorstore


def demo_2_knowledge_base():
    """æ¼”ç¤ºåˆ›å»ºçŸ¥è¯†åº“"""
    print("\n" + "=" * 60)
    print("Demo 2: åˆ›å»ºå…¬å¸çŸ¥è¯†åº“")
    print("=" * 60)
    
    vectorstore = create_knowledge_base()
    
    print("å·²åˆ›å»ºçŸ¥è¯†åº“ï¼ŒåŒ…å«ä»¥ä¸‹æ–‡æ¡£ï¼š")
    print("  - è¯·å‡ç›¸å…³ï¼šè¯·å‡æµç¨‹ã€å¹´å‡è§„å®šã€ç—…å‡è§„å®š")
    print("  - æŠ¥é”€ç›¸å…³ï¼šæŠ¥é”€æµç¨‹ã€å·®æ—…æ ‡å‡†")
    print("  - ITç›¸å…³ï¼šVPNä½¿ç”¨ã€ç”µè„‘æ•…éšœ")
    print("  - è¡Œæ”¿ç›¸å…³ï¼šä¼šè®®å®¤é¢„çº¦")
    
    # æµ‹è¯•æ£€ç´¢
    print("\næµ‹è¯•æ£€ç´¢ï¼š")
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    
    test_queries = ["æ€ä¹ˆè¯·å‡", "å‡ºå·®ä½å®¿æ ‡å‡†å¤šå°‘", "ç”µè„‘åäº†æ€ä¹ˆåŠ"]
    for query in test_queries:
        docs = retriever.invoke(query)
        print(f"\n  Q: {query}")
        print(f"  A: {docs[0].page_content[:60]}...")
    
    return vectorstore


# ============================================================
# Demo 3: æŠŠ RAG å°è£…æˆ Tool
# ============================================================

def demo_3_rag_as_tool():
    """æŠŠ RAG å°è£…æˆ Agent å¯ç”¨çš„å·¥å…·"""
    print("\n" + "=" * 60)
    print("Demo 3: æŠŠ RAG å°è£…æˆ Tool")
    print("=" * 60)
    
    from langchain_core.tools import tool
    
    # åˆ›å»ºçŸ¥è¯†åº“
    vectorstore = create_knowledge_base()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    
    # æ–¹å¼1ï¼šç®€å•å°è£… - ç›´æ¥è¿”å›æ£€ç´¢ç»“æœ
    @tool
    def search_company_docs(query: str) -> str:
        """æœç´¢å…¬å¸å†…éƒ¨æ–‡æ¡£ï¼ŒåŒ…æ‹¬è¯·å‡åˆ¶åº¦ã€æŠ¥é”€æµç¨‹ã€ITæŒ‡å—ç­‰ã€‚
        å½“ç”¨æˆ·è¯¢é—®å…¬å¸ç›¸å…³æ”¿ç­–ã€æµç¨‹ã€è§„å®šæ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼Œå¦‚"è¯·å‡æµç¨‹"ã€"æŠ¥é”€æ ‡å‡†"ç­‰
        """
        docs = retriever.invoke(query)
        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        
        results = []
        for i, doc in enumerate(docs):
            results.append(f"[{i+1}] {doc.page_content}")
        return "\n\n".join(results)
    
    print("åˆ›å»ºäº† RAG å·¥å…·: search_company_docs")
    print(f"  æè¿°: {search_company_docs.description[:50]}...")
    
    # æµ‹è¯•å·¥å…·
    print("\næµ‹è¯•å·¥å…·è°ƒç”¨ï¼š")
    result = search_company_docs.invoke("å¹´å‡æœ‰å¤šå°‘å¤©")
    print(f"  è¾“å…¥: 'å¹´å‡æœ‰å¤šå°‘å¤©'")
    print(f"  è¾“å‡º: {result[:100]}...")
    
    return search_company_docs, vectorstore


# ============================================================
# Demo 4: Agent + RAG å®æˆ˜
# ============================================================

def demo_4_agent_with_rag():
    """Agent ä½¿ç”¨ RAG å·¥å…·"""
    print("\n" + "=" * 60)
    print("Demo 4: Agent + RAG å®æˆ˜")
    print("=" * 60)
    
    from langchain_core.tools import tool
    from langchain_core.messages import HumanMessage, SystemMessage
    from langgraph.prebuilt import create_react_agent
    
    # åˆ›å»ºçŸ¥è¯†åº“å’Œ RAG å·¥å…·
    vectorstore = create_knowledge_base()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    
    @tool
    def search_company_docs(query: str) -> str:
        """æœç´¢å…¬å¸å†…éƒ¨æ–‡æ¡£ï¼ŒåŒ…æ‹¬è¯·å‡åˆ¶åº¦ã€æŠ¥é”€æµç¨‹ã€ITæŒ‡å—ã€è¡Œæ”¿è§„å®šç­‰ã€‚
        å½“ç”¨æˆ·è¯¢é—®å…¬å¸æ”¿ç­–ã€æµç¨‹ã€è§„å®šæ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚"""
        docs = retriever.invoke(query)
        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        return "\n\n".join([f"[æ¥æº:{doc.metadata.get('source', 'æœªçŸ¥')}] {doc.page_content}" for doc in docs])
    
    # åˆ›å»ºå…¶ä»–å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰
    @tool
    def submit_leave_request(days: int, reason: str) -> str:
        """æäº¤è¯·å‡ç”³è¯·ã€‚
        
        Args:
            days: è¯·å‡å¤©æ•°
            reason: è¯·å‡åŸå› 
        """
        return f"âœ… è¯·å‡ç”³è¯·å·²æäº¤ï¼š{days}å¤©ï¼ŒåŸå› ï¼š{reason}ã€‚ç­‰å¾…é¢†å¯¼å®¡æ‰¹ã€‚"
    
    @tool
    def book_meeting_room(room: str, time: str) -> str:
        """é¢„çº¦ä¼šè®®å®¤ã€‚
        
        Args:
            room: ä¼šè®®å®¤åç§°ï¼Œå¦‚"å¤§ä¼šè®®å®¤"ã€"å°ä¼šè®®å®¤A"
            time: é¢„çº¦æ—¶é—´ï¼Œå¦‚"æ˜å¤©ä¸‹åˆ2ç‚¹"
        """
        return f"âœ… ä¼šè®®å®¤é¢„çº¦æˆåŠŸï¼š{room}ï¼Œæ—¶é—´ï¼š{time}"
    
    @tool
    def get_current_time() -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # åˆ›å»º Agent
    llm = get_llm()
    tools = [search_company_docs, submit_leave_request, book_meeting_room, get_current_time]
    
    system_prompt = """ä½ æ˜¯å…¬å¸æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©å‘˜å·¥ï¼š
1. æŸ¥è¯¢å…¬å¸åˆ¶åº¦å’Œæµç¨‹ï¼ˆä½¿ç”¨ search_company_docs å·¥å…·ï¼‰
2. æäº¤è¯·å‡ç”³è¯·ï¼ˆä½¿ç”¨ submit_leave_request å·¥å…·ï¼‰
3. é¢„çº¦ä¼šè®®å®¤ï¼ˆä½¿ç”¨ book_meeting_room å·¥å…·ï¼‰
4. æŸ¥è¯¢å½“å‰æ—¶é—´ï¼ˆä½¿ç”¨ get_current_time å·¥å…·ï¼‰

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚å¦‚æœéœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œè¯·é€æ­¥å®Œæˆã€‚
å›ç­”æ—¶è¯·ç®€æ´æ˜äº†ï¼Œç›´æ¥ç»™å‡ºç»“æœã€‚"""
    
    agent = create_react_agent(llm, tools, prompt=system_prompt)
    
    # æµ‹è¯•åœºæ™¯
    test_cases = [
        # åœºæ™¯1ï¼šç®€å•æŸ¥è¯¢ï¼ˆåªéœ€è¦ RAGï¼‰
        "å…¬å¸å¹´å‡æ˜¯æ€ä¹ˆè§„å®šçš„ï¼Ÿ",
        
        # åœºæ™¯2ï¼šå¤åˆä»»åŠ¡ï¼ˆRAG + å…¶ä»–å·¥å…·ï¼‰
        "æˆ‘æƒ³è¯·2å¤©å‡å»æ—…æ¸¸ï¼Œè¯·å…ˆå‘Šè¯‰æˆ‘è¯·å‡æµç¨‹ï¼Œç„¶åå¸®æˆ‘æäº¤ç”³è¯·",
        
        # åœºæ™¯3ï¼šä¸éœ€è¦ RAG çš„ä»»åŠ¡
        "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ",
    ]
    
    print("Agent å·¥å…·åˆ—è¡¨ï¼š")
    for t in tools:
        print(f"  - {t.name}: {t.description[:40]}...")
    
    for i, query in enumerate(test_cases):
        print(f"\n{'â”€' * 50}")
        print(f"åœºæ™¯ {i+1}: {query}")
        print("â”€" * 50)
        
        result = agent.invoke({"messages": [HumanMessage(content=query)]})
        
        # æ˜¾ç¤º Agent çš„æ€è€ƒè¿‡ç¨‹
        for msg in result["messages"]:
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    print(f"  ğŸ”§ è°ƒç”¨å·¥å…·: {tc['name']}")
                    print(f"     å‚æ•°: {tc['args']}")
            elif msg.type == "tool":
                print(f"  ğŸ“‹ å·¥å…·è¿”å›: {msg.content[:80]}...")
            elif msg.type == "ai" and msg.content:
                print(f"\n  ğŸ¤– Agent å›ç­”: {msg.content}")


# ============================================================
# Demo 5: å¸¦ Memory çš„ RAG Agent
# ============================================================

def demo_5_rag_agent_with_memory():
    """å¸¦è®°å¿†çš„ RAG Agentï¼Œæ”¯æŒå¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("Demo 5: å¸¦ Memory çš„ RAG Agent")
    print("=" * 60)
    
    from langchain_core.tools import tool
    from langchain_core.messages import HumanMessage
    from langgraph.prebuilt import create_react_agent
    from langgraph.checkpoint.memory import MemorySaver
    
    # åˆ›å»ºçŸ¥è¯†åº“
    vectorstore = create_knowledge_base()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    
    @tool
    def search_company_docs(query: str) -> str:
        """æœç´¢å…¬å¸å†…éƒ¨æ–‡æ¡£ï¼ŒåŒ…æ‹¬è¯·å‡ã€æŠ¥é”€ã€ITã€è¡Œæ”¿ç­‰åˆ¶åº¦ã€‚"""
        docs = retriever.invoke(query)
        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        return "\n\n".join([doc.page_content for doc in docs])
    
    # åˆ›å»ºå¸¦ Memory çš„ Agent
    llm = get_llm()
    memory = MemorySaver()
    
    agent = create_react_agent(
        llm, 
        [search_company_docs],
        prompt="ä½ æ˜¯å…¬å¸æ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©å‘˜å·¥æŸ¥è¯¢å…¬å¸åˆ¶åº¦ã€‚è¯·ç®€æ´å›ç­”ã€‚",
        checkpointer=memory
    )
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    config = {"configurable": {"thread_id": "user_001"}}
    
    conversation = [
        "è¯·å‡éœ€è¦æå‰å‡ å¤©ç”³è¯·ï¼Ÿ",
        "é‚£ç—…å‡å‘¢ï¼Ÿéœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ",  # è¿½é—®ï¼ŒAgent éœ€è¦è®°ä½ä¸Šä¸‹æ–‡
        "å¥½çš„ï¼Œ500å…ƒä»¥ä¸Šçš„æŠ¥é”€è°å®¡æ‰¹ï¼Ÿ",  # åˆ‡æ¢è¯é¢˜
    ]
    
    print("å¤šè½®å¯¹è¯æ¼”ç¤ºï¼š\n")
    for query in conversation:
        print(f"ğŸ‘¤ ç”¨æˆ·: {query}")
        result = agent.invoke({"messages": [HumanMessage(content=query)]}, config)
        
        # è·å–æœ€åçš„ AI å›ç­”
        ai_response = result["messages"][-1].content
        print(f"ğŸ¤– åŠ©æ‰‹: {ai_response}\n")


# ============================================================
# Demo 6: é«˜çº§æŠ€å·§ - è‡ªå®šä¹‰ RAG Chain ä½œä¸ºå·¥å…·
# ============================================================

def demo_6_advanced_rag_tool():
    """æ›´é«˜çº§çš„ RAG å·¥å…·ï¼šå¸¦å¼•ç”¨æ¥æº"""
    print("\n" + "=" * 60)
    print("Demo 6: é«˜çº§ RAG å·¥å…·ï¼ˆå¸¦å¼•ç”¨æ¥æºï¼‰")
    print("=" * 60)
    
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.messages import HumanMessage
    from langgraph.prebuilt import create_react_agent
    
    # åˆ›å»ºçŸ¥è¯†åº“
    vectorstore = create_knowledge_base()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    llm = get_llm()
    
    # åˆ›å»ºå¸¦å¼•ç”¨çš„ RAG Chain
    rag_prompt = ChatPromptTemplate.from_template("""
æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ã€‚è¯·åœ¨å›ç­”æœ«å°¾æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. åªæ ¹æ®æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ 
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´"æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. åœ¨å›ç­”æœ«å°¾ç”¨ã€æ¥æºï¼šxxxã€‘æ ‡æ³¨ä¿¡æ¯æ¥æº
""")
    
    @tool
    def search_with_citation(query: str) -> str:
        """æœç´¢å…¬å¸æ–‡æ¡£å¹¶è¿”å›å¸¦å¼•ç”¨æ¥æºçš„ç­”æ¡ˆã€‚
        æ¯”æ™®é€šæœç´¢æ›´å¯é ï¼Œä¼šæ ‡æ³¨ä¿¡æ¯æ¥æºã€‚"""
        # æ£€ç´¢
        docs = retriever.invoke(query)
        if not docs:
            return "æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        
        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦æ¥æºæ ‡æ³¨ï¼‰
        context_parts = []
        for doc in docs:
            source = doc.metadata.get("source", "æœªçŸ¥")
            context_parts.append(f"[æ¥æº:{source}]\n{doc.page_content}")
        context = "\n\n".join(context_parts)
        
        # ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ
        chain = rag_prompt | llm | StrOutputParser()
        answer = chain.invoke({"context": context, "question": query})
        return answer
    
    # åˆ›å»º Agent
    agent = create_react_agent(
        llm, 
        [search_with_citation],
        prompt="ä½ æ˜¯å…¬å¸åŠ©æ‰‹ã€‚ä½¿ç”¨ search_with_citation å·¥å…·æŸ¥è¯¢å…¬å¸åˆ¶åº¦ï¼Œè¯¥å·¥å…·ä¼šè¿”å›å¸¦å¼•ç”¨æ¥æºçš„å‡†ç¡®ç­”æ¡ˆã€‚"
    )
    
    # æµ‹è¯•
    test_queries = [
        "å‡ºå·®ä½å®¿æ ‡å‡†æ˜¯å¤šå°‘ï¼Ÿ",
        "VPNæ€ä¹ˆä½¿ç”¨ï¼Ÿ",
    ]
    
    print("å¸¦å¼•ç”¨æ¥æºçš„ RAG å›ç­”ï¼š\n")
    for query in test_queries:
        print(f"Q: {query}")
        result = agent.invoke({"messages": [HumanMessage(content=query)]})
        answer = result["messages"][-1].content
        print(f"A: {answer}\n")


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

if __name__ == "__main__":
    if not IFLOW_API_KEY:
        print("é”™è¯¯: è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® IFLOW_API_KEY")
        exit(1)
    
    print("=" * 60)
    print("Agent + RAG ç»“åˆæ•™ç¨‹")
    print("=" * 60)
    print(f"å¯¹è¯æ¨¡å‹: {IFLOW_MODEL}")
    print(f"Embedding: {SILICONFLOW_EMBEDDING_MODEL if SILICONFLOW_API_KEY else 'æœ¬åœ°æ¨¡å‹'}")
    
    demo_1_difference()
    demo_2_knowledge_base()
    demo_3_rag_as_tool()
    demo_4_agent_with_rag()
    demo_5_rag_agent_with_memory()
    demo_6_advanced_rag_tool()
    
    print("\n" + "=" * 60)
    print("Agent + RAG æ•™ç¨‹å®Œæˆï¼")
    print("=" * 60)
    print("""
æ ¸å¿ƒè¦ç‚¹ï¼š

1. Agent + RAG vs å•çº¯ RAG
   - å•çº¯ RAGï¼šæ¯æ¬¡éƒ½æ£€ç´¢ï¼Œåªèƒ½å›ç­”çŸ¥è¯†åº“é—®é¢˜
   - Agent + RAGï¼šè‡ªä¸»å†³å®šæ˜¯å¦æ£€ç´¢ï¼Œå¯ç»„åˆå¤šå·¥å…·

2. RAG ä½œä¸º Tool çš„å°è£…æ–¹å¼
   - ç®€å•å°è£…ï¼šç›´æ¥è¿”å›æ£€ç´¢ç»“æœ
   - é«˜çº§å°è£…ï¼šRAG Chain + å¼•ç”¨æ¥æº

3. å®é™…åº”ç”¨æ¨¡å¼
   - æ™ºèƒ½å®¢æœï¼šæŸ¥çŸ¥è¯†åº“ + åˆ›å»ºå·¥å•
   - ä¼ä¸šåŠ©æ‰‹ï¼šæŸ¥æ–‡æ¡£ + æ‰§è¡Œæ“ä½œ
   - å¤šè½®å¯¹è¯ï¼šMemory + RAG

é¢è¯•è¦ç‚¹ï¼š
- Agent å’Œ RAG å¦‚ä½•ç»“åˆï¼Ÿï¼ˆRAG ä½œä¸º Toolï¼‰
- ä»€ä¹ˆæ—¶å€™ç”¨ Agent + RAGï¼Ÿï¼ˆéœ€è¦å¤šå·¥å…·åä½œã€è‡ªä¸»å†³ç­–æ—¶ï¼‰

ä¸‹ä¸€æ­¥ï¼šå­¦ä¹ æ›´å¤æ‚çš„ Agent æ¶æ„ï¼ˆPlan-Executeã€Multi-Agentï¼‰
""")
