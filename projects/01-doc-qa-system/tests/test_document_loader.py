"""
DocumentLoader å•å…ƒæµ‹è¯•
"""

import sys
from pathlib import Path

# æ·»åŠ  src è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import pytest
from document_loader import DocumentLoader


class TestDocumentLoader:
    """DocumentLoader æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def loader(self):
        """åˆ›å»º DocumentLoader å®ä¾‹"""
        return DocumentLoader(chunk_size=200, chunk_overlap=20)
    
    def test_load_text_content_basic(self, loader):
        """æµ‹è¯•åŸºæœ¬æ–‡æœ¬åŠ è½½"""
        text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚"
        docs = loader.load_text_content(text, {"source": "test"})
        
        assert len(docs) >= 1
        assert docs[0].page_content == text
        assert docs[0].metadata["source"] == "test"
    
    def test_load_text_content_with_chunking(self, loader):
        """æµ‹è¯•æ–‡æœ¬åˆ‡åˆ†"""
        # åˆ›å»ºä¸€ä¸ªè¶…è¿‡ chunk_size çš„æ–‡æœ¬
        text = "è¿™æ˜¯ç¬¬ä¸€æ®µå†…å®¹ã€‚" * 50 + "\n\n" + "è¿™æ˜¯ç¬¬äºŒæ®µå†…å®¹ã€‚" * 50
        docs = loader.load_text_content(text, {"source": "test"})
        
        # åº”è¯¥è¢«åˆ‡åˆ†æˆå¤šä¸ªå—
        assert len(docs) > 1
        
        # æ¯ä¸ªå—çš„å¤§å°åº”è¯¥ä¸è¶…è¿‡ chunk_sizeï¼ˆå…è®¸ä¸€å®šè¯¯å·®ï¼‰
        for doc in docs:
            assert len(doc.page_content) <= loader.text_splitter._chunk_size + 50
    
    def test_load_text_content_preserves_metadata(self, loader):
        """æµ‹è¯•å…ƒæ•°æ®ä¿ç•™"""
        text = "æµ‹è¯•æ–‡æœ¬"
        metadata = {"source": "test", "author": "tester", "version": "1.0"}
        docs = loader.load_text_content(text, metadata)
        
        assert docs[0].metadata["source"] == "test"
        assert docs[0].metadata["author"] == "tester"
        assert docs[0].metadata["version"] == "1.0"
    
    def test_load_text_content_empty(self, loader):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        text = ""
        docs = loader.load_text_content(text, {"source": "test"})
        
        # ç©ºæ–‡æœ¬åº”è¯¥è¿”å›ç©ºåˆ—è¡¨æˆ–å•ä¸ªç©ºæ–‡æ¡£
        assert len(docs) <= 1
    
    def test_chunk_overlap(self):
        """æµ‹è¯• chunk_overlap å‚æ•°"""
        loader = DocumentLoader(chunk_size=100, chunk_overlap=20)
        
        # åˆ›å»ºä¸€ä¸ªéœ€è¦åˆ‡åˆ†çš„æ–‡æœ¬
        text = "A" * 150
        docs = loader.load_text_content(text, {"source": "test"})
        
        if len(docs) > 1:
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å ï¼ˆç¬¬ä¸€ä¸ªå—çš„æœ«å°¾åº”è¯¥å‡ºç°åœ¨ç¬¬äºŒä¸ªå—çš„å¼€å¤´ï¼‰
            first_end = docs[0].page_content[-20:]
            second_start = docs[1].page_content[:20]
            # ç”±äºåˆ‡åˆ†ç­–ç•¥ï¼Œå¯èƒ½ä¸å®Œå…¨é‡å ï¼Œä½†åº”è¯¥æœ‰ä¸€äº›é‡å 
            assert len(docs) >= 2
    
    def test_supported_formats(self, loader):
        """æµ‹è¯•æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        supported = loader.get_supported_formats()
        
        assert ".pdf" in supported
        assert ".md" in supported
        assert ".txt" in supported
        assert ".docx" in supported
    
    def test_load_nonexistent_file(self, loader):
        """æµ‹è¯•åŠ è½½ä¸å­˜åœ¨çš„æ–‡ä»¶"""
        with pytest.raises(FileNotFoundError):
            loader.load_file("/nonexistent/path/file.txt")
    
    def test_load_unsupported_format(self, loader, tmp_path):
        """æµ‹è¯•åŠ è½½ä¸æ”¯æŒçš„æ ¼å¼"""
        # åˆ›å»ºä¸€ä¸ªä¸æ”¯æŒçš„æ–‡ä»¶
        unsupported_file = tmp_path / "test.xyz"
        unsupported_file.write_text("test content")
        
        with pytest.raises(ValueError):
            loader.load_file(str(unsupported_file))
    
    def test_load_txt_file(self, loader, tmp_path):
        """æµ‹è¯•åŠ è½½ TXT æ–‡ä»¶"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        txt_file = tmp_path / "test.txt"
        txt_file.write_text("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶çš„å†…å®¹ã€‚\nåŒ…å«å¤šè¡Œæ–‡æœ¬ã€‚")
        
        docs = loader.load_file(str(txt_file))
        
        assert len(docs) >= 1
        assert "æµ‹è¯•æ–‡ä»¶" in docs[0].page_content
    
    def test_load_markdown_file(self, loader, tmp_path):
        """æµ‹è¯•åŠ è½½ Markdown æ–‡ä»¶"""
        md_file = tmp_path / "test.md"
        md_file.write_text("# æ ‡é¢˜\n\nè¿™æ˜¯æ­£æ–‡å†…å®¹ã€‚\n\n## å­æ ‡é¢˜\n\næ›´å¤šå†…å®¹ã€‚")
        
        docs = loader.load_file(str(md_file))
        
        assert len(docs) >= 1
        assert "æ ‡é¢˜" in docs[0].page_content or "æ­£æ–‡" in docs[0].page_content


class TestDocumentLoaderEdgeCases:
    """è¾¹ç•Œæƒ…å†µæµ‹è¯•"""
    
    def test_very_small_chunk_size(self):
        """æµ‹è¯•éå¸¸å°çš„ chunk_size"""
        loader = DocumentLoader(chunk_size=10, chunk_overlap=2)
        text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•å°å—åˆ‡åˆ†ã€‚"
        docs = loader.load_text_content(text, {"source": "test"})
        
        # åº”è¯¥è¢«åˆ‡åˆ†æˆå¤šä¸ªå°å—
        assert len(docs) > 1
    
    def test_large_overlap(self):
        """æµ‹è¯•å¤§çš„ overlap"""
        loader = DocumentLoader(chunk_size=100, chunk_overlap=80)
        text = "A" * 200
        docs = loader.load_text_content(text, {"source": "test"})
        
        # åº”è¯¥æ­£å¸¸å·¥ä½œ
        assert len(docs) >= 1
    
    def test_unicode_content(self):
        """æµ‹è¯• Unicode å†…å®¹"""
        loader = DocumentLoader(chunk_size=200, chunk_overlap=20)
        text = "ä¸­æ–‡å†…å®¹ ğŸ‰ Emoji æµ‹è¯• æ—¥æœ¬èª í•œêµ­ì–´"
        docs = loader.load_text_content(text, {"source": "test"})
        
        assert len(docs) >= 1
        assert "ä¸­æ–‡" in docs[0].page_content
        assert "ğŸ‰" in docs[0].page_content


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
